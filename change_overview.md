# ä¿®æ”¹æ–¹æ¡ˆ

## å¤šä»»åŠ¡å­¦ä¹ æ–¹å‘

æ”¹ä¸ºå…±äº«ç¼–ç å™¨ï¼Œå¢åŠ ç‰¹å¾é€‰æ‹©æ¨¡å—

è®¾è¾“å…¥æ•°æ®å¤§å°ï¼š
$$
X \in \mathbb{R}^{B\times C\times H\times W}
$$
ç¼–ç å™¨ç”± L=5 ä¸ªå°ºåº¦ç»„æˆï¼Œè®¾å…±äº«ç¼–ç å™¨è¾“å‡ºï¼š
$$
\{ f_1, f_2, f_3, f_4, f_5 \} = \mathcal{E}(\mathbf{x})
$$
å…¶ä¸­ï¼š
$$
f_i \in \mathbb{R}^{B \times C_i \times H_i \times W_i}, \quad H_i = \frac{H}{2^{i-1}},\; W_i = \frac{W}{2^{i-1}}
$$

> æ ‡å‡† UNet encoder çš„å¤šå°ºåº¦è¾“å‡ºã€‚

å®šä¹‰ä»»åŠ¡é›†åˆï¼š
$$
{T} = \{ \text{seg}, \text{sdf}, \text{bnd} \}
$$



### æ–¹æ¡ˆä¸€ï¼šå°ºåº¦å†… Task-wise DWConv ç‰¹å¾é€‰æ‹©ï¼ˆScale-wise Task-aware Feature Selectionï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

> åœ¨**æ¯ä¸€ä¸ªå°ºåº¦å†…éƒ¨**ï¼Œä¸º**æ¯ä¸€ä¸ªä»»åŠ¡**å­¦ä¹ ä¸€ä¸ª**é€åƒç´ æƒé‡å›¾**ï¼Œç”¨äºé€‰æ‹©è¯¥å°ºåº¦ä¸­â€œå“ªäº›ä½ç½®ã€å“ªäº›è¯­ä¹‰é€šé“å¯¹è¯¥ä»»åŠ¡æ›´é‡è¦â€ã€‚

#### 1 å°ºåº¦å†… Task-wise DWConv

å¯¹ä»»æ„å°ºåº¦ iå’Œä»»åŠ¡ $$t \in \mathcal{T}$$ï¼Œå®šä¹‰ä¸€ä¸ª **Depthwise Convolution Selector**ï¼š
$$
w_i^{(t)} = \mathcal{DWConv}_i^{(t)}(f_i)
$$
è¾“å‡ºæƒé‡å›¾ï¼š
$$
w_i^{(t)} \in \mathbb{R}^{B \times 1 \times H_i \times W_i}
$$


> **å…³é”®ç‚¹**ï¼š
>
> - æƒé‡æ˜¯ **é€åƒç´ ï¼ˆpixel-wiseï¼‰**
> - ä¸æ”¹å˜ç©ºé—´åˆ†è¾¨ç‡
> - ä¸æ··åˆé€šé“ï¼ˆDWConvï¼‰



#### 2 å°ºåº¦å†…ç‰¹å¾è°ƒåˆ¶ï¼ˆFeature Modulationï¼‰

å°†æƒé‡ä½œç”¨åˆ°åŸå§‹ç‰¹å¾ä¸Šï¼š
$$
f_i^{(t)} = w_i^{(t)} \odot f_i
$$
å…¶ä¸­ï¼š

- $\odot$è¡¨ç¤ºé€å…ƒç´ å¹¿æ’­ä¹˜æ³•

ç»“æœç‰¹å¾ç»´åº¦ä¿æŒä¸å˜ï¼š
$$
f_i^{(t)} \in \mathbb{R}^{B \times C_i \times H_i \times W_i}
$$

#### 3 decoderä½¿ç”¨

å¯¹æ¯ä¸ªä»»åŠ¡ tï¼Œæœ€ç»ˆé€å…¥ decoder çš„ç‰¹å¾é›†åˆä¸ºï¼š
$$
{\mathcal{F}}^{(t)} = \{ \hat f_1^{(t)}, \hat f_2^{(t)}, \hat f_3^{(t)}, \hat f_4^{(t)}, \hat f_5^{(t)} \}
$$
éšåè¿›å…¥ä»»åŠ¡ä¸“å± decoderï¼š
$$
\mathbf{y}^{(t)} = \mathcal{D}^{(t)}\left( \hat{\mathcal{F}}^{(t)} \right)
$$
å…¶ä¸­ï¼š

- $\mathcal{D}^{(t)}$ï¼šUNet Decoderï¼ˆç»“æ„ç›¸åŒï¼Œå‚æ•°ä¸å…±äº«ï¼‰
- $\mathbf{y}^{(t)}$ï¼šä»»åŠ¡è¾“å‡ºï¼ˆseg mask / sdf / boundaryï¼‰

#### å¯¹æ¯”

åŸå§‹ UNetï¼ˆå•ä»»åŠ¡ï¼‰
$$
\mathbf{y} = \mathcal{D} \big( \{ f_i \}_{i=1}^5 \big)
$$


æœ¬æ–¹æ¡ˆï¼ˆå¤šä»»åŠ¡ï¼‰
$$
\mathbf{y}^{(t)} = \mathcal{D}^{(t)} \big( \{ w_i^{(t)} \odot f_i \}_{i=1}^5 \big)
$$
ğŸ‘‰ **åŒºåˆ«ä»…åœ¨äº**ï¼š
 åœ¨ encoder ä¸ decoder ä¹‹é—´æ’å…¥äº†ä¸€ä¸ª **task-conditioned multiplicative gating**ã€‚

> æˆ‘ä»¬æå‡ºäº†ä¸€ç§å°ºåº¦æ„ŸçŸ¥ã€ä»»åŠ¡æ„ŸçŸ¥çš„ç‰¹å¾é€‰æ‹©æ¨¡å—ï¼Œè¯¥æ¨¡å—é€šè¿‡è½»é‡çº§çš„æ·±åº¦å·ç§¯æ¥è°ƒæ•´å…±äº«ç¼–ç å™¨ç‰¹å¾ï¼Œä½¿æ¯ä¸ªä»»åŠ¡èƒ½å¤Ÿåœ¨æ¯ä¸ªåˆ†è¾¨ç‡ä¸‹æœ‰é€‰æ‹©åœ°å…³æ³¨ç©ºé—´ç›¸å…³ä¿¡æ¯ã€‚

#### æ¬¡ç”Ÿæ–¹æ¡ˆ

æ–¹æ¡ˆä¸€ + f4/f5 çº¦æŸï¼Œf4å’Œf5å±äºé«˜å±‚è¯­ä¹‰ï¼Œç‰¹å¾æå–æˆ–è®¸æ„ä¹‰ä¸å¤§ï¼Œæ‰€ä»¥é‡‡å–ä¸åŒæ–¹å¼ç‰¹å¾æå–

f1-f3:ç”¨æ–¹æ¡ˆä¸€

f4-f5:ç”¨æ–¹æ¡ˆäºŒ

æ–¹æ¡ˆäºŒgatingè®¾è®¡ä¸­ï¼Œé™¤äº†é€‰æ‹©åçš„ç‰¹å¾å›¾ï¼Œè¿˜å¯ä»¥åŠ ä¸ŠåŸå§‹ç‰¹å¾å›¾ï¼Œå®ç°ä¸“å®¶é—´å…¨å±€ä¿¡æ¯å…±äº«

---

### æ–¹æ¡ˆäºŒï¼šLow-rank approximation of task-wise feature selection

è®°å¾—ç»§ç»­ç¡®å®šKçš„å–å€¼

å¯¹ **æ¯ä¸€ä¸ªå°ºåº¦ $f_i$**ï¼Œæˆ‘ä»¬åšå¦‚ä¸‹æ“ä½œï¼š

> **å…±äº« K ä¸ªå°ºåº¦ä¸“å®¶ï¼ˆDWConvï¼‰ + ä»»åŠ¡æ¡ä»¶ gating**

å¯¹å•å°ºåº¦ï¼ˆç¬¬ i å±‚ï¼‰ç»“æ„è®¾è®¡ï¼š

#### 1 å…±äº«ä¸“å®¶ï¼ˆShared Expertsï¼‰

ä¸ºç¬¬ i ä¸ªå°ºåº¦å®šä¹‰ **K ä¸ªå…±äº« DWConv ä¸“å®¶**ï¼š
$$
e_{i,k} = \phi_{i,k}(f_i), \quad k = 1,\dots,K
$$
å…¶ä¸­ï¼š

- $\phi_{i,k}$ï¼š$Depthwise Convï¼ˆkernel = 3Ã—3ï¼‰$
- è¾“å‡ºç»´åº¦ä¸å˜ï¼š

$$
e_{i,k} \in \mathbb{R}^{B \times C_i \times H_i \times W_i}
$$



> ğŸ”‘ è¿™äº›ä¸“å®¶ **ä¸åŒºåˆ†ä»»åŠ¡**ï¼Œå®ƒä»¬å­¦ä¹ çš„æ˜¯ï¼š

- è¾¹ç¼˜å‹
- åŒºåŸŸå‹
- æ–¹å‘æ€§
- ç©ºæ´ç»“æ„
- è¿é€šæ€§
  ç­‰**é€šç”¨åŒ»å­¦è§†è§‰åŸè¯­**

å…·ä½“å®é™…ï¼Œè®¾K=4ï¼Œå¢åŠ  **ä¸“å®¶ç†µ / åˆ©ç”¨ç‡çš„ logging å…¬å¼**ä½œä¸ºæŒ‡æ ‡ï¼š

**æ–¹æ¡ˆ 2-Aï¼šæ— å…ˆéªŒä¸“å®¶ï¼ˆæœ€å¹²å‡€ï¼‰**

æ¯ä¸ªå°ºåº¦ iï¼š
$$
\{ e_{i,1}, e_{i,2}, \dots, e_{i,K} \}, \quad e_{i,k} = \text{DWConv}_{3\times3}(f_i)
$$
ç‰¹ç‚¹ï¼š

- å®Œå…¨æ•°æ®é©±åŠ¨
- ä¸ Low-Rank Experts åŸæ–‡æœ€ä¸€è‡´
- æ¶ˆèæ—¶æœ€å®¹æ˜“è¯´æ˜â€œ**ä¸“å®¶ç»„åˆèƒ½åŠ›**â€

**æ–¹æ¡ˆ 2-Bï¼šå¼±å…ˆéªŒä¸“å®¶ï¼ˆå¯è§£é‡Šæ€§æ›´å¼ºï¼‰**

ç»™ä¸åŒä¸“å®¶ä¸åŒ kernel / dilationï¼š

| Expert     | è®¾è®¡                   | è¯­ä¹‰        |
| ---------- | ---------------------- | ----------- |
| eâ‚         | DWConv 3Ã—3             | å±€éƒ¨çº¹ç†    |
| eâ‚‚         | DWConv 3Ã—3, dilation=2 | ä¸­å°ºåº¦ç»“æ„  |
| eâ‚ƒ         | DWConv 5Ã—5 æˆ–å †å       | å¹³æ»‘ / åŒºåŸŸ |
| eâ‚„ï¼ˆå¯é€‰ï¼‰ | identity               | åŸå§‹ç‰¹å¾    |

ç‰¹ç‚¹ï¼š

- ä¸“å®¶è¯­ä¹‰å¯è§£é‡Š
- å¯¹ reviewer å‹å¥½
- ä½†ç¨å¾®å¼•å…¥ inductive bias

ğŸ“Œ **å¯ä½œä¸ºè¡¥å……å®éªŒ**

#### 2 ä»»åŠ¡ gatingï¼ˆTask-conditioned Mixingï¼‰

å¯¹äºæ¯ä¸ªä»»åŠ¡ $t \in \{\text{seg}, \text{sdf}, \text{bnd}\}$ï¼Œå¼•å…¥ä¸€ä¸ªè½»é‡ gatingï¼š

**gating è¾“å…¥**

ä½ æœ‰ä¸‰ç§åˆç†é€‰æ‹©ï¼ˆæŒ‰æ¨èåº¦ï¼‰ï¼š

**æ¨è Aï¼ˆæœ€ç¨³ï¼‰**ï¼š
$$
g_i^{(t)} = \text{Conv}_{1\times1}^{(t)}(f_i)
$$
**å¯é€‰ Bï¼ˆæ›´è½»ï¼‰**ï¼š
$$
g_i^{(t)} = \text{MLP}(\text{GAP}(f_i))
$$
**å¯é€‰ Cï¼ˆtask embeddingï¼‰**ï¼š
$$
g_i^{(t)} = \text{MLP}([ \text{GAP}(f_i), \mathbf{e}_t ])
$$
**gating è¾“å‡º**
$$
\alpha_i^{(t)} = \text{softmax}_k(g_i^{(t)}) \in \mathbb{R}^{B \times K \times H_i \times W_i}
$$


- softmax åœ¨ **K ç»´åº¦**,è¡¨ç¤ºï¼š**è¯¥ä»»åŠ¡åœ¨è¯¥åƒç´ å¤„â€œè°ƒç”¨å“ªäº›ä¸“å®¶â€**

#### 3 Low-rank ä¸“å®¶èåˆï¼ˆå…³é”®å…¬å¼ï¼‰

$$
w_i^{(t)} = \sum_{k=1}^{K} \alpha_{i,k}^{(t)} \odot e_{i,k}
$$

å¾—åˆ°ï¼š
$$
w_i^{(t)} \in \mathbb{R}^{B \times C_i \times H_i \times W_i}
$$
è¿™æ˜¯ **ä»»åŠ¡ t åœ¨å°ºåº¦ i ä¸Šçš„â€œé€‰åç‰¹å¾â€**ã€‚

#### 4 è·¨å°ºåº¦æ•´åˆï¼ˆä¸æ–¹æ¡ˆä¸€å®Œå…¨ä¸€è‡´ï¼‰

ä½ æœ‰ä¸¤ç§æ–¹å¼ï¼ˆä¸æ–¹æ¡ˆä¸€å…¼å®¹ï¼‰ï¼š

âœ”ï¸ æ–¹å¼ Aï¼šç›´æ¥é€å…¥ task decoder
$$
\{w_i^{(t)}\}_{i=1}^{5} \rightarrow \text{UNetDecoder}^{(t)}
$$
æ¯ä¸ªä»»åŠ¡ä¸€ä¸ª decoderï¼ˆç»“æ„ç›¸åŒï¼Œå‚æ•°ä¸å…±äº«ï¼‰ã€‚



âœ”ï¸ æ–¹å¼ Bï¼šåªåœ¨ f1â€“f3 ä½¿ç”¨ LREï¼ˆæ¨èï¼‰
$$
\tilde f_i^{(t)} = \begin{cases} w_i^{(t)}, & i \le 3 \\ f_i, & i > 3 \end{cases}
$$
å†é€å…¥ decoderï¼Œ**ç¨³å®šæ€§æ›´å¼º**ã€‚



#### æŸå¤±å‡½æ•°å¿…é¡»é¢å¤–è€ƒè™‘çš„ç‚¹

âœ… (A) ä¸“å®¶å¤šæ ·æ€§æ­£åˆ™ï¼ˆ**å¼ºçƒˆå»ºè®®**ï¼‰

æ­£äº¤ / ç›¸å…³æ€§çº¦æŸ
$$
{L}_{orth} = \sum_i \sum_{k \neq k'} \frac{ \langle e_{i,k}, e_{i,k'} \rangle }{\|e_{i,k}\|\|e_{i,k'}\|}
$$


- é˜²æ­¢ä¸“å®¶è¶‹åŒ
- Low-Rank Experts / MoE å¸¸ç”¨

æƒé‡å»ºè®®ï¼š
$$
\lambda_{orth} \approx 10^{-3}
$$

------

âœ… (B) gating ç†µæ­£åˆ™ï¼ˆæ¯”æ–¹æ¡ˆä¸€æ›´é‡è¦ï¼‰
$$
{L}_{ent}^{gate} = \sum \text{Entropy}(\alpha^{(t)})
$$
å¦åˆ™ï¼š

- gating ä¼šé€‰åŒä¸€ä¸ªä¸“å®¶
- MoE åå­˜å®äº¡

#### stop-gradientï¼š

æ–¹æ¡ˆ 2-Aï¼ˆæ¨èï¼‰ï¼š

> **gating ä¸åå‘æ›´æ–° encoder**

**å¥½å¤„**ï¼š

- encoder å­¦â€œé€šç”¨è¡¨å¾â€
- gating å­¦â€œä»»åŠ¡è·¯ç”±â€
- ç¨³å®šæ€§æ˜¾è‘—æé«˜ï¼ˆè¿™æ˜¯ MoE å®æˆ˜ç»éªŒï¼‰

---

### æ–¹æ¡ˆä¸‰ï¼šPatcher-style Decoderï¼ˆSingle-stage Task-wise Gated Fusionï¼‰

#### 1 ç©ºé—´å¯¹é½

é€‰æ‹©ä¸€ä¸ª**ç»Ÿä¸€ç›®æ ‡å°ºåº¦**ï¼ˆæ¨èï¼‰ï¼š
$$
H^\* = H_1,\quad W^\* = W_1
$$
å¯¹æ¯ä¸ªå°ºåº¦ï¼š
$$
\tilde f_i = \text{Up}(f_i) \in \mathbb{R}^{B \times C_i \times H^\* \times W^\*}
$$
ğŸ“Œ ä¸Šé‡‡æ ·æ–¹å¼ï¼š

- bilinear / nearest
- **æ— å‚æ•°ï¼Œæ¢¯åº¦ç¨³å®š**

é€šé“å¯¹é½ï¼ˆå¯é€‰ä½†æ¨èï¼‰

ä¸ºäº†é¿å…åç»­ gating å‚æ•°çˆ†ç‚¸ï¼š
$$
f_i = \phi_i(\tilde f_i), \quad \phi_i = \text{1Ã—1 Conv},\quad \hat f_i \in \mathbb{R}^{B \times C \times H^\* \times W^\*}
$$

#### 2 å°ºåº¦æ‹¼æ¥ï¼ˆPatcher-style aggregationï¼‰

$$
F = \text{Concat}(\hat f_1, \hat f_2, \dots, \hat f_5) \in \mathbb{R}^{B \times (5C) \times H^\* \times W^\*}
$$

è¿™é‡Œçš„ F å°±æ˜¯ **â€œPatcher è¾“å…¥ token mapâ€ çš„ç­‰ä»·å½¢å¼**ï¼š

- æ¯ä¸ªç©ºé—´ä½ç½® = ä¸€ä¸ª multi-scale token
- token å« 5 ä¸ªå°ºåº¦çš„ä¿¡æ¯

#### 3 Task-wise DWConv Gatingï¼ˆæ ¸å¿ƒï¼‰

å¯¹æ¯ä¸ªä»»åŠ¡ $t \in \{\text{seg, sdf, bnd}\}$ï¼Œå®šä¹‰ä¸€ä¸ª gatingï¼š
$$
G^{(t)} = \text{DWConv}^{(t)}(F) \in \mathbb{R}^{B \times (5C) \times H^\* \times W^\*}
$$
ç‰¹ç‚¹ï¼š

- **Depthwise**ï¼šæ¯ä¸ªé€šé“ç‹¬ç«‹å»ºæ¨¡
- **é€åƒç´ **ï¼šç©ºé—´è‡ªé€‚åº”
- **ä»»åŠ¡æ¡ä»¶åŒ–**

**gating å½’ä¸€åŒ–ï¼ˆæ¨èï¼‰**

å¯¹å°ºåº¦ç»´åº¦åš softmaxï¼š

å°†$G^{(t)}$reshape ä¸ºï¼š
$$
G^{(t)} \rightarrow \mathbb{R}^{B \times C \times 5 \times H^\* \times W^\*}
$$
ç„¶åï¼š
$$
\alpha_{i}^{(t)} = \text{Softmax}_i(G^{(t)})
$$

#### 4 ä»»åŠ¡ç‰¹å®šç‰¹å¾èåˆ

å¯¹æ¯ä¸ªä»»åŠ¡ï¼š
$$
F^{(t)} = \sum_{i=1}^5 \alpha_i^{(t)} \odot \hat f_i \quad\in \mathbb{R}^{B \times C \times H^\* \times W^\*}
$$
è§£é‡Šï¼š

- æ¯ä¸ªåƒç´ 
- å¯¹ 5 ä¸ªå°ºåº¦è‡ªé€‚åº”åŠ æƒ
- æƒé‡éšä»»åŠ¡å˜åŒ–

ğŸ“Œ **è¿™ä¸€æ­¥å®Œå…¨ç­‰ä»·äº Patcher çš„ token mixingï¼Œä½†æ›´è½»**

#### 5 å•é˜¶æ®µè§£ç ï¼ˆæç®€ï¼‰

ä½ æå‡ºçš„æ˜¯ï¼š

> ã€Œç›´æ¥ä¸€æ¬¡ Up_conv + è¾“å‡ºå¤´ã€

å•å±‚ refinementï¼ˆå¯é€‰ï¼‰
$$
\bar F^{(t)} = \text{Conv}_{3\times3}(F^{(t)})
$$
è¾“å‡ºå¤´
$$
y^{(t)} = \text{Head}^{(t)}(\bar F^{(t)})
$$


- segï¼šsigmoid / softmax
- sdfï¼šregression head
- bndï¼šbinary / multi-class

```markdown
x
 â†“
Shared U-Net Encoder
 â†“
{f1,f2,f3,f4,f5}
 â†“ (upsample + 1Ã—1)
{fÌ‚1,...,fÌ‚5}
 â†“ concat
F (multi-scale token map)
 â†“ DWConv gating (task-wise)
{Î±seg, Î±sdf, Î±bnd}
 â†“ weighted sum
{Fseg, Fsdf, Fbnd}
 â†“ single conv + head
{Å·seg, Å·sdf, Å·bnd}
```

#### æŸå¤±å‡½æ•°å¿…é¡»é¢å¤–è€ƒè™‘çš„ç‚¹

âœ… (A) ä»»åŠ¡æƒé‡å¿…é¡»åŠ¨æ€ / å¯å­¦ä¹ 

ä½ ç°åœ¨ç”¨çš„ï¼š

```
MultiTaskLoss (uncertainty-based)
```

ğŸ‘‰ **éå¸¸åˆé€‚æ–¹æ¡ˆä¸‰**

ç†ç”±ï¼š

- è‡ªåŠ¨æŠ‘åˆ¶ä¸ç¨³å®šä»»åŠ¡
- é˜²æ­¢æŸä»»åŠ¡ä¸»å¯¼ encoder

âœ… (B) gating æ­£åˆ™å¿…é¡»ä¿ç•™

è‡³å°‘è¦æœ‰ï¼š

- ç†µæ­£åˆ™
- å°ºåº¦å¹³æ»‘

å¦åˆ™ Patcher gating ä¼šé€€åŒ–ä¸ºï¼š

> â€œå›ºå®šçº¿æ€§æŠ•å½±â€

#### stop-gradient

å»ºè®®ï¼š

> **gating è¾“å…¥å¯¹ encoder stop-grad**

ç†ç”±ï¼š

- å¦åˆ™ encoder ä¼šâ€œè¿åˆ gatingâ€
- å•é˜¶æ®µ decoder éå¸¸å®¹æ˜“ä¸ç¨³å®š

---



### å®éªŒå‘½å

#### **E1 â€“ TaskDW (Full-scale Task-wise Selection)**

**æ–¹æ¡ˆä¸€ï¼ˆåŸºçº¿ï¼‰**

> f1â€“f5 å…¨å°ºåº¦ Task-wise DWConv ç‰¹å¾é€‰æ‹©

**å…³é”®è¯**

- Task-wise
- Scale-wise
- No expert sharing

**è®ºæ–‡å†™æ³•**

> *E1: Task-wise Depthwise Convolution on All Encoder Scales*

------

#### **E2 â€“ LRE-Free (Low-Rank Experts, No Prior)**

**æ–¹æ¡ˆäºŒï¼ˆæ— å…ˆéªŒä¸“å®¶ï¼‰**

> å…±äº«ä¸“å®¶ + ä»»åŠ¡ gating
> encoder stop-grad + expert æ­£åˆ™ + gating æ­£åˆ™

**å…³é”®è¯**

- Low-Rank Experts
- No prior
- Structure-only

**è®ºæ–‡å†™æ³•**

> *E2: Low-Rank Experts without Expert Prior*

------

#### **E3 â€“ LRE-Prior (Low-Rank Experts with Weak Prior)**

**æ–¹æ¡ˆäºŒï¼ˆå¼±å…ˆéªŒä¸“å®¶ï¼‰**

> åœ¨ E2 åŸºç¡€ä¸ŠåŠ å¼± inductive bias

**è®ºæ–‡å†™æ³•**

> *E3: Low-Rank Experts with Weak Task Prior*

------

#### **E4 â€“ Hybrid-High (DW + LRE on High-level Scales)**

**æ··åˆæ–¹æ¡ˆï¼ˆf5 ä½¿ç”¨ä¸“å®¶ï¼‰**

> f1â€“f4ï¼šTaskDW
> f5ï¼šLow-Rank Experts

**è®ºæ–‡å†™æ³•**

> *E4: Hybrid Feature Selection with Experts on High-level Scales*

------

#### **E5 â€“ Hybrid-MidHigh (DW + LRE on Mid/High Scales)**

**æ··åˆæ–¹æ¡ˆï¼ˆf4â€“f5 ä½¿ç”¨ä¸“å®¶ï¼‰**

> f1â€“f3ï¼šTaskDW
> f4â€“f5ï¼šLow-Rank Experts

**è®ºæ–‡å†™æ³•**

> *E5: Hybrid Feature Selection with Experts on Mid-to-High Scales*

------

#### **E6 â€“ PatchGate (Patcher-style Single-stage Decoder)**

**æ–¹æ¡ˆä¸‰**

> å•é˜¶æ®µ Task-wise gated fusion
> encoder stop-grad

**è®ºæ–‡å†™æ³•**

> *E6: Single-stage Task-wise Gated Decoder*

------

ğŸ’¡ **å»ºè®®**

- æ—¥å¿—ç›®å½•ï¼š`logs/E1_TaskDW/`
- æ¨¡å‹åï¼š`model_E2_LREFree.pth`
- è¡¨æ ¼è¡Œåï¼š`E4 (Hybrid-High)`

---

### ä»£ç 

#### ğŸŒ¿ `feat-select-base`

**å…¬å…±åŸºç¡€åˆ†æ”¯ï¼ˆéå¸¸å…³é”®ï¼‰**

åœ¨è¿™é‡Œï¼š

- åŠ  `TaskDWSelector`
- åŠ  `DWExpert`
- åŠ  `TaskGating`
- åŠ  `FeatureAggregator`
- **ä¸æ¥å…¥è®­ç»ƒæµç¨‹**

ğŸ‘‰ åé¢æ‰€æœ‰å®éªŒéƒ½ä»è¿™åˆ‡

------

#### ğŸŒ¿ `exp-E1-taskdw`

- å¯ç”¨ TaskDWSelector
- f1â€“f5
- ä¸ç”¨ä¸“å®¶

------

#### ğŸŒ¿ `exp-E2-lre-free`

- K experts
- gating
- encoder stop-grad
- æ­£åˆ™

------

#### ğŸŒ¿ `exp-E3-lre-prior`

- åœ¨ E2 åŸºç¡€ä¸ŠåŠ  prior
- åªåŠ¨ selector / gating

------

#### ğŸŒ¿ `exp-E4-hybrid-high`

- f1â€“f4 TaskDW
- f5 LRE

------

#### ğŸŒ¿ `exp-E5-hybrid-mid-high`

- f1â€“f3 TaskDW
- f4â€“f5 LRE

------

#### ğŸŒ¿ `exp-E6-patchgate`

- å•é˜¶æ®µ decoder
- ä¸èµ° unet decoder

äºŒã€å¿…é¡»é¢„ç•™çš„ã€Œé…ç½®æ¥å£ã€

config.yaml / args

```
FEATURE_SELECT:
  ENABLE: true
  TYPE: task_dw | lowrank | hybrid | patchgate
  EXPERT_K: 3
  STOP_GRAD_ENCODER: true
  SCALE_MODE: full | high | mid_high
```

------

train.py ä¸­ç»Ÿä¸€å…¥å£


**æ¶æ„å·¥ç¨‹å±‚é¢çš„å…³é”®æ­¥éª¤**ã€‚

> âœ… å»ºä¸€ä¸ªçº¯â€œèƒ½åŠ›åˆ†æ”¯â€
> âŒ ä¸æ”¹åŸè®­ç»ƒæµç¨‹
> âŒ ä¸æ¥å…¥ forward ä¸»å¹²
> âœ… åªæä¾›å¯å¤ç”¨æ¨¡å—

åé¢ E1â€“E6 å…¨éƒ¨ä»è¿™ä¸ªåˆ†æ”¯åˆ‡ã€‚

ä¸‹é¢ç»™ä½ ä¸€ä¸ª**å·¥ç¨‹çº§è®¾è®¡æ–¹æ¡ˆ**ï¼ˆæ¥å£ + ç»“æ„ + forward é€»è¾‘ï¼‰å‚è€ƒï¼Œä¿è¯ï¼š

* å¯æ‰©å±•åˆ° 3 ä¸ªæ–¹æ¡ˆ
* æ”¯æŒ stop-grad
* æ”¯æŒ low-rank ä¸“å®¶
* æ”¯æŒ gating æ­£åˆ™
* ä¸å’Œç°æœ‰æ¨¡å‹è€¦åˆ

---
# ä¸€ã€ç›®å½•ç»“æ„å»ºè®®

åœ¨ models ä¸‹æ–°å»ºï¼š

```text
models/
    modules/
        feat_select/
            __init__.py
            dwconv.py
            task_dw_selector.py
            task_gating.py
            feature_aggregator.py
```

---

# äºŒã€æ¨¡å— 1ï¼šDWConv

## åŠŸèƒ½

æœ€åŸºç¡€æ„ä»¶ï¼š

* depthwise 3Ã—3 conv
* å¯é€‰ BN
* å¯é€‰ activation
* ä¿æŒè¾“å…¥è¾“å‡º channel ä¸€è‡´

---

## è®¾è®¡

```python
# dwconv.py

import torch
import torch.nn as nn
import torch.nn.functional as F


class DWConv(nn.Module):
    """
    Basic Depthwise Convolution block.

    Args:
        in_channels (int)
        kernel_size (int)
        use_bn (bool)
        activation (str): 'relu' | 'gelu' | None
    """

    def __init__(
        self,
        in_channels,
        kernel_size=3,
        use_bn=True,
        activation='relu'
    ):
        super().__init__()

        padding = kernel_size // 2

        self.dwconv = nn.Conv2d(
            in_channels,
            in_channels,
            kernel_size=kernel_size,
            padding=padding,
            groups=in_channels,
            bias=not use_bn
        )

        self.bn = nn.BatchNorm2d(in_channels) if use_bn else nn.Identity()

        if activation == 'relu':
            self.act = nn.ReLU(inplace=True)
        elif activation == 'gelu':
            self.act = nn.GELU()
        else:
            self.act = nn.Identity()

    def forward(self, x):
        x = self.dwconv(x)
        x = self.bn(x)
        x = self.act(x)
        return x
```

---

# ä¸‰ã€æ¨¡å— 2ï¼šTaskDWSelectorï¼ˆæ–¹æ¡ˆä¸€æ ¸å¿ƒï¼‰

## åŠŸèƒ½

> æ¯ä¸ªä»»åŠ¡ä¸€ä¸ª DWConv
> è¾“å‡ºä½œä¸ºæƒé‡å›¾ or ç›´æ¥åŠ æƒ

æ”¯æŒï¼š

* task æ•°é‡
* stop_grad encoder feature
* è¾“å‡ºæƒé‡ or è¾“å‡ºé‡åŠ æƒç‰¹å¾

---

## è®¾è®¡

```python
# task_dw_selector.py

import torch
import torch.nn as nn
import torch.nn.functional as F
from .dwconv import DWConv


class TaskDWSelector(nn.Module):
    """
    Scale-wise Task-specific DWConv selector.

    Args:
        in_channels (int)
        num_tasks (int)
        return_weight (bool): 
            True -> return weight map
            False -> return reweighted feature
        detach_input (bool): whether to stop-grad encoder feature
    """

    def __init__(
        self,
        in_channels,
        num_tasks,
        return_weight=False,
        detach_input=False
    ):
        super().__init__()

        self.num_tasks = num_tasks
        self.return_weight = return_weight
        self.detach_input = detach_input

        self.task_dw = nn.ModuleList([
            DWConv(in_channels) for _ in range(num_tasks)
        ])

        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        """
        x: [B, C, H, W]
        returns:
            weights or reweighted features
        """

        if self.detach_input:
            x = x.detach()

        outputs = []

        for dw in self.task_dw:
            weight = self.sigmoid(dw(x))

            if self.return_weight:
                outputs.append(weight)
            else:
                outputs.append(weight * x)

        return outputs  # list length = num_tasks
```

---

# å››ã€æ¨¡å— 3ï¼šTaskGatingï¼ˆæ–¹æ¡ˆäºŒæ ¸å¿ƒï¼‰

æ”¯æŒä¸‰ç§ gating å½¢å¼ï¼š

* conv 1x1
* MLP(GAP)
* MLP(GAP + task embedding)

ç»Ÿä¸€æ¥å£ã€‚

---

## è®¾è®¡

```python
# task_gating.py

import torch
import torch.nn as nn
import torch.nn.functional as F


class TaskGating(nn.Module):
    """
    Generic Task Gating Module.

    mode:
        'conv'
        'mlp'
        'mlp_task_emb'
    """

    def __init__(
        self,
        in_channels,
        num_experts,
        num_tasks,
        mode='conv',
        hidden_dim=128
    ):
        super().__init__()

        self.mode = mode
        self.num_tasks = num_tasks
        self.num_experts = num_experts

        if mode == 'conv':
            self.gates = nn.ModuleList([
                nn.Conv2d(in_channels, num_experts, kernel_size=1)
                for _ in range(num_tasks)
            ])

        elif mode == 'mlp':
            self.gates = nn.ModuleList([
                nn.Sequential(
                    nn.Linear(in_channels, hidden_dim),
                    nn.ReLU(),
                    nn.Linear(hidden_dim, num_experts)
                )
                for _ in range(num_tasks)
            ])

        elif mode == 'mlp_task_emb':
            self.task_embedding = nn.Embedding(num_tasks, hidden_dim)

            self.gates = nn.ModuleList([
                nn.Sequential(
                    nn.Linear(in_channels + hidden_dim, hidden_dim),
                    nn.ReLU(),
                    nn.Linear(hidden_dim, num_experts)
                )
                for _ in range(num_tasks)
            ])

    def forward(self, x):
        """
        x: [B, C, H, W]
        return:
            list of gating weights (softmax over experts)
        """

        B, C, H, W = x.shape
        outputs = []

        for t in range(self.num_tasks):

            if self.mode == 'conv':
                g = self.gates[t](x)  # [B, K, H, W]

            else:
                gap = F.adaptive_avg_pool2d(x, 1).view(B, C)

                if self.mode == 'mlp':
                    g = self.gates[t](gap).unsqueeze(-1).unsqueeze(-1)

                else:
                    task_emb = self.task_embedding(
                        torch.full((B,), t, device=x.device)
                    )
                    inp = torch.cat([gap, task_emb], dim=1)
                    g = self.gates[t](inp).unsqueeze(-1).unsqueeze(-1)

            g = F.softmax(g, dim=1)

            outputs.append(g)

        return outputs
```

---

# äº”ã€æ¨¡å— 4ï¼šFeatureAggregatorï¼ˆä¸“å®¶ç»„åˆå™¨ï¼‰

ç”¨äºï¼š

> w = Î£ Î±_k e_k

æ”¯æŒ spatial / non-spatialã€‚

---

## è®¾è®¡

```python
# feature_aggregator.py

import torch
import torch.nn as nn


class FeatureAggregator(nn.Module):
    """
    Combine expert outputs using gating weights.

    experts: list of expert modules
    """

    def __init__(self, experts):
        super().__init__()
        self.experts = nn.ModuleList(experts)

    def forward(self, x, gating_weights):
        """
        x: [B, C, H, W]
        gating_weights: list length=num_tasks
                        each: [B, K, H, W] or [B, K, 1, 1]

        return:
            list of aggregated features
        """

        expert_outputs = [e(x) for e in self.experts]  # K

        expert_stack = torch.stack(expert_outputs, dim=1)
        # shape: [B, K, C, H, W]

        outputs = []

        for g in gating_weights:
            g = g.unsqueeze(2)  # [B, K, 1, H, W]
            weighted = (g * expert_stack).sum(dim=1)
            outputs.append(weighted)

        return outputs
```

---
ä½ ç°åœ¨æ‹¥æœ‰ï¼š

* æ–¹æ¡ˆä¸€æ„ä»¶
* æ–¹æ¡ˆäºŒæ„ä»¶
* æ–¹æ¡ˆä¸‰æ‰€éœ€ gating åŸºç¡€
* stop-grad èƒ½åŠ›
* å¯æ’æ‹”ä¸“å®¶ç»“æ„

---
# æ–¹æ¡ˆä¸€å®æ–½æ–¹æ¡ˆ
å¾ˆå¥½ï¼Œç°åœ¨æˆ‘ä»¬è¿›å…¥ **E1ï¼ˆæ–¹æ¡ˆä¸€ï¼‰çš„å·¥ç¨‹è½åœ°è§„åˆ’é˜¶æ®µ**ã€‚
ç›®æ ‡éå¸¸æ˜ç¡®ï¼š

> âœ… å®ç° Scale-wise TaskDWSelector
> âœ… æ’å…¥ encoder â†’ decoder ä¹‹é—´
> âœ… ä¸ç ´åç°æœ‰è®­ç»ƒæµç¨‹
> âœ… ä¸º E4/E5ï¼ˆæ··åˆæ–¹æ¡ˆï¼‰å’Œæ–¹æ¡ˆäºŒé¢„ç•™æ¥å£

ä¸‹é¢æˆ‘æŒ‰ **å·¥ç¨‹æ­¥éª¤ â†’ æ¯æ­¥æ–°å¢æ¨¡å— â†’ é¢„ç•™æ‰©å±•ç‚¹ â†’ æ³¨æ„äº‹é¡¹** ç»™ä½ ä¸€ä¸ªå®Œæ•´å®æ–½è·¯å¾„ã€‚

---

# ä¸€ã€æ€»ä½“æ”¹é€ è·¯å¾„ï¼ˆéå¸¸é‡è¦ï¼‰

ä½ ç°åœ¨çš„ç»“æ„å¤§æ¦‚ç‡æ˜¯ï¼š

```
x â†’ encoder â†’ {f1,f2,f3,f4,f5}
    â†’ decoder_seg
    â†’ decoder_sdf
    â†’ decoder_bnd
```

æˆ‘ä»¬è¦å˜æˆï¼š

```
x â†’ encoder â†’ {f1,...,f5}
    â†’ MultiScaleTaskSelector
        â†’ {f1^(t),...,f5^(t)}
    â†’ decoder_t
```

ä½†è¦åšåˆ°ï¼š

* Selector æ˜¯å¯å¼€å…³çš„
* é»˜è®¤è¡Œä¸º = æ’ç­‰æ˜ å°„
* åç»­å¯ä»¥æ›¿æ¢ f4/f5 ä¸ºä¸“å®¶æ¨¡å—

---

# äºŒã€E1 å®ç°æ­¥éª¤è§„åˆ’ï¼ˆæ¨èæŒ‰é¡ºåºï¼‰

---

# Step 1ï¸âƒ£ï¼šåˆ›å»º MultiScaleTaskSelectorï¼ˆæ€»æ§æ¨¡å—ï¼‰

è¿™æ˜¯æ•´ä¸ªæ–¹æ¡ˆä¸€çš„æ ¸å¿ƒã€‚

## ç›®æ ‡

* ç®¡ç† f1â€“f5
* æ¯ä¸ªå°ºåº¦ç‹¬ç«‹ TaskDWSelector
* è¾“å‡ºç»“æ„æ¸…æ™°
* æ”¯æŒ scale-level åˆ‡æ¢ï¼ˆä¸ºæ··åˆæ–¹æ¡ˆé¢„ç•™ï¼‰

---

## è®¾è®¡

```python
class MultiScaleTaskSelector(nn.Module):
    """
    Apply Task-wise DW feature selection on multi-scale features.

    Args:
        in_channels_list: list of channel numbers for f1-f5
        num_tasks: int
        mode: 'task_dw' | 'hybrid'
        hybrid_scales: list of scale indices using expert (e.g., [4,5])
    """

    def __init__(
        self,
        in_channels_list,
        num_tasks,
        mode='task_dw',
        hybrid_scales=None
    ):
        super().__init__()

        self.num_tasks = num_tasks
        self.mode = mode
        self.hybrid_scales = hybrid_scales or []

        self.selectors = nn.ModuleList()

        for i, c in enumerate(in_channels_list):
            scale_id = i + 1

            if mode == 'task_dw' or scale_id not in self.hybrid_scales:
                self.selectors.append(
                    TaskDWSelector(
                        in_channels=c,
                        num_tasks=num_tasks,
                        return_weight=False
                    )
                )
            else:
                # é¢„ç•™ä¸“å®¶ç»“æ„ï¼ˆæš‚æ—¶ä¸å®ç°ï¼‰
                self.selectors.append(None)

    def forward(self, features):
        """
        features: list [f1,...,f5]
        return:
            task_features: list length=num_tasks
                each element = list of 5 features
        """

        task_features = [
            [] for _ in range(self.num_tasks)
        ]

        for i, f in enumerate(features):

            selector = self.selectors[i]

            if selector is not None:
                outputs = selector(f)
            else:
                # placeholder (hybrid future)
                outputs = [f for _ in range(self.num_tasks)]

            for t in range(self.num_tasks):
                task_features[t].append(outputs[t])

        return task_features
```

---

## è¿™ä¸ªæ¨¡å—çš„æ„ä¹‰

å®ƒæ˜¯ï¼š

> **E1 / E4 / E5 çš„ç»Ÿä¸€å…¥å£**

åé¢ï¼š

* f4-f5 ç”¨ä¸“å®¶ï¼Ÿ
* åªæ”¹è¿™ä¸ªæ¨¡å—
* decoder ä¸åŠ¨
* encoder ä¸åŠ¨

---

# Step 2ï¸âƒ£ï¼šä¿®æ”¹ä¸»æ¨¡å‹ forwardï¼ˆè½»æ”¹åŠ¨ï¼‰

å‡è®¾åŸæ¥ï¼š

```python
features = self.encoder(x)
out_seg = self.decoder_seg(features)
```

æ”¹ä¸ºï¼š

```python
features = self.encoder(x)

if self.use_feat_selector:
    task_features = self.selector(features)
else:
    task_features = [features] * self.num_tasks

out_seg = self.decoder_seg(task_features[0])
out_sdf = self.decoder_sdf(task_features[1])
out_bnd = self.decoder_bnd(task_features[2])
```

---

## å…³é”®è¦æ±‚

* ä¸æ”¹ decoder ç»“æ„
* decoder ä»ç„¶æ¥æ”¶ list[f1â€“f5]
* selector å¼€å…³å¯æ§

---

# Step 3ï¸âƒ£ï¼šå‚æ•°æ¥å£è®¾è®¡ï¼ˆå¿…é¡»åšï¼‰

åœ¨ config ä¸­åŠ å…¥ï¼š

```yaml
FEATURE_SELECT:
  ENABLE: true
  TYPE: task_dw
  HYBRID_SCALES: []
```

æ¨¡å‹åˆå§‹åŒ–ï¼š

```python
if cfg.FEATURE_SELECT.ENABLE:
    self.selector = MultiScaleTaskSelector(
        in_channels_list=[c1,c2,c3,c4,c5],
        num_tasks=3,
        mode=cfg.FEATURE_SELECT.TYPE,
        hybrid_scales=cfg.FEATURE_SELECT.HYBRID_SCALES
    )
```

---

# Step 4ï¸âƒ£ï¼šä¸ºæ¬¡ç”Ÿæ–¹æ¡ˆé¢„ç•™æ¥å£

ä½ æå‡ºä¸¤ä¸ªæ¬¡ç”Ÿç‚¹ï¼š

---

## æ¬¡ç”Ÿæ–¹æ¡ˆ A

> f4/f5 ç”¨ä¸“å®¶

å·²ç»åœ¨ï¼š

```
hybrid_scales=[4,5]
```

ä¸­é¢„ç•™ã€‚

æœªæ¥åªéœ€ï¼š

```python
if scale_id in hybrid_scales:
    use ExpertSelector
```

---

## æ¬¡ç”Ÿæ–¹æ¡ˆ B

> ä¸“å®¶è¾“å‡º + åŸå§‹ç‰¹å¾å…±äº«

æå‰è®¾è®¡ FeatureAggregator æ¥å£ï¼š

```python
aggregated = sum(alpha_k * expert_k)
if self.add_residual:
    aggregated = aggregated + x
```

å»ºè®®åœ¨ ExpertSelector å†…éƒ¨ç•™ï¼š

```python
self.use_residual = True
```

---

# Step 5ï¸âƒ£ï¼šæ­£åˆ™ç»Ÿè®¡æ¥å£ï¼ˆç°åœ¨å°±åŠ ï¼‰

éå¸¸å…³é”®ã€‚

åœ¨ TaskDWSelector ä¸­åŠ å…¥ï¼š

```python
self.last_weight_maps = []
```

forward ä¸­ï¼š

```python
self.last_weight_maps.append(weight)
```

æœªæ¥ï¼š

* entropy loss
* å¯è§†åŒ–
* collapse æ£€æµ‹

ä¸ç”¨å†æ”¹ç»“æ„ã€‚

---

# ä¸‰ã€E1 å®Œæ•´æ”¹é€ æµç¨‹æ€»ç»“

| æ­¥éª¤ | æ”¹åŠ¨èŒƒå›´                      | é£é™© |
| -- | ------------------------- | -- |
| 1  | æ–°å»º MultiScaleTaskSelector | æ—   |
| 2  | ä¸»æ¨¡å‹ forward åŠ  selector    | ä½  |
| 3  | config åŠ å¼€å…³                | æ—   |
| 4  | é¢„ç•™ hybrid_scales          | æ—   |
| 5  | æ­£åˆ™ç»Ÿè®¡æ¥å£                    | æ—   |

---

# å››ã€éå¸¸å…³é”®çš„è®¾è®¡åŸåˆ™

ç°åœ¨åš E1 æ—¶å¿…é¡»æ»¡è¶³ï¼š

* âŒ ä¸åœ¨ decoder å†…å†™ gating
* âŒ ä¸æ”¹å˜ encoder
* âŒ ä¸ hardcode ä»»åŠ¡æ•°é‡
* âœ… selector æ˜¯ plug-in
* âœ… å¯ä»¥ä¸€è¡Œå…³æ‰

---

# äº”ã€E1 å®ç°åçš„ç»“æ„å›¾ï¼ˆä»£ç çº§ï¼‰

```
Encoder
  â†“
[f1,f2,f3,f4,f5]
  â†“
MultiScaleTaskSelector
  â†“
[
  [f1_seg,...,f5_seg],
  [f1_sdf,...,f5_sdf],
  [f1_bnd,...,f5_bnd]
]
  â†“
Decoder_seg / sdf / bnd
```

---

# å…­ã€ä¸‹ä¸€æ­¥å»ºè®®

ç°åœ¨æœ€æ­£ç¡®çš„æ¨è¿›æ–¹å¼ï¼š

1ï¸âƒ£ å…ˆåªå®ç° E1
2ï¸âƒ£ è·‘é€š
3ï¸âƒ£ ç¡®è®¤ loss æ­£å¸¸ä¸‹é™
4ï¸âƒ£ æ‰“å°æƒé‡ç»Ÿè®¡

ç„¶åæˆ‘ä»¬å†åšï¼š

* E2 ä¸“å®¶æ¨¡å—æ’å…¥
* æˆ– f4/f5 hybrid

---




